{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:36:26.770004Z","iopub.status.busy":"2024-03-28T15:36:26.769541Z","iopub.status.idle":"2024-03-28T15:36:39.822983Z","shell.execute_reply":"2024-03-28T15:36:39.822052Z","shell.execute_reply.started":"2024-03-28T15:36:26.769970Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","tf.config.experimental.list_physical_devices()"]},{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-28T15:36:47.062230Z","iopub.status.busy":"2024-03-28T15:36:47.061598Z","iopub.status.idle":"2024-03-28T15:37:14.373412Z","shell.execute_reply":"2024-03-28T15:37:14.372386Z","shell.execute_reply.started":"2024-03-28T15:36:47.062199Z"},"trusted":true},"outputs":[],"source":["import os\n","\n","os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n","\n","import argparse\n","import pandas as pd\n","import xml.etree.ElementTree as ET\n","import matplotlib.pyplot as plt \n","import matplotlib.patches as patches\n","\n","import numpy as np\n","import cv2\n","from glob import glob\n","from tensorflow.keras.callbacks import ModelCheckpoint, CSVLogger, ReduceLROnPlateau, EarlyStopping, TensorBoard\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.losses import BinaryCrossentropy, SparseCategoricalCrossentropy,CategoricalCrossentropy\n","from sklearn.preprocessing import LabelEncoder\n","\n","from tqdm import tqdm\n","from sklearn.metrics import accuracy_score\n","from tensorflow.keras.models import load_model, Model\n","# from tensorflow.keras import models\n","from tensorflow.keras.layers import *\n","\n","\n","def xml_to_csv(path):\n","    xml_list = []\n","    for file in os.scandir(path):\n","        if file.is_file() and file.name.endswith(('.xml')):\n","            xml_file = os.path.join(path, file.name)\n","            tree = ET.parse(xml_file)\n","            root = tree.getroot()\n","            for member in root.findall('object'):\n","                value = (root.find('filename').text,\n","                        int(root.find('size')[0].text),\n","                        int(root.find('size')[1].text),\n","                        member[0].text,\n","                        int(member[5][0].text),\n","                        int(member[5][1].text),\n","                        int(member[5][2].text),\n","                        int(member[5][3].text) )\n","                xml_list.append(value)\n","\n","    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'xmax', 'ymin', 'ymax']\n","    xml_df = pd.DataFrame(xml_list, columns=column_name)\n","    return xml_df\n","\n","\n","if __name__ == \"__main__\":\n","    path_train = '/kaggle/input/custom-dataset-new/train'\n","    path_valid = '/kaggle/input/custom-dataset-new/valid'\n","    path_test = '/kaggle/input/custom-dataset-new/test'\n","    \n","    train = xml_to_csv(path_train)\n","    valid = xml_to_csv(path_valid)\n","    test = xml_to_csv(path_test)\n","    \n","    print('Successfully converted xml to csv.')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:37:16.349580Z","iopub.status.busy":"2024-03-28T15:37:16.348358Z","iopub.status.idle":"2024-03-28T15:37:16.365978Z","shell.execute_reply":"2024-03-28T15:37:16.364979Z","shell.execute_reply.started":"2024-03-28T15:37:16.349548Z"},"trusted":true},"outputs":[],"source":["train.head()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:37:30.658152Z","iopub.status.busy":"2024-03-28T15:37:30.657495Z","iopub.status.idle":"2024-03-28T15:37:30.672813Z","shell.execute_reply":"2024-03-28T15:37:30.671894Z","shell.execute_reply.started":"2024-03-28T15:37:30.658121Z"},"trusted":true},"outputs":[],"source":["label_encoder = LabelEncoder()\n","original_values = train['class'].unique()\n","\n","train['class_encoded'] = label_encoder.fit_transform(train['class'])\n","valid['class_encoded'] = label_encoder.fit_transform(valid['class'])\n","test['class_encoded'] = label_encoder.fit_transform(test['class'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:37:34.870498Z","iopub.status.busy":"2024-03-28T15:37:34.869803Z","iopub.status.idle":"2024-03-28T15:37:34.888024Z","shell.execute_reply":"2024-03-28T15:37:34.887092Z","shell.execute_reply.started":"2024-03-28T15:37:34.870468Z"},"trusted":true},"outputs":[],"source":["pre_dict = train[['class', 'class_encoded']].drop_duplicates()\n","class_dict= pd.Series(pre_dict.class_encoded.values, index=pre_dict['class']).to_dict()\n","class_dict = sorted(class_dict.items(), key=lambda x:x[1])\n","class_dict = dict(class_dict)\n","class_dict"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:37:43.242525Z","iopub.status.busy":"2024-03-28T15:37:43.241782Z","iopub.status.idle":"2024-03-28T15:37:48.869578Z","shell.execute_reply":"2024-03-28T15:37:48.868129Z","shell.execute_reply.started":"2024-03-28T15:37:43.242495Z"},"trusted":true},"outputs":[],"source":["def ShowImage(data, path, number=None):\n","    fig, axes = plt.subplots(number, 2, figsize=(20, 60))\n","    for i in range(number):  \n","        img = plt.imread(os.path.join(path, data['filename'][i]))\n","        x, y, width, height  = data['xmin'][i], data['ymin'][i], data['xmax'][i]-data['xmin'][i], data['ymax'][i]-data['ymin'][i]\n","        rect = patches.Rectangle((x, y),\n","                             width, height,\n","                             linewidth = 2,\n","                             edgecolor = 'r',\n","                             facecolor = 'none')\n","        axes[i, 0].imshow(img)\n","        axes[i, 1].imshow(img)\n","        axes[i, 1].add_patch(rect)\n","        axes[i, 0].set_title(train['class'][i])\n","        axes[i, 1].set_title(train['class'][i])\n","        axes[i, 0].axis(\"off\")\n","        axes[i, 1].axis(\"off\")\n","    plt.tight_layout()\n","    plt.show()\n","\n","if __name__ == \"__main__\":\n","    ShowImage(train , path_train, number=6) "]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:38:35.616400Z","iopub.status.busy":"2024-03-28T15:38:35.615659Z","iopub.status.idle":"2024-03-28T15:38:35.948391Z","shell.execute_reply":"2024-03-28T15:38:35.947386Z","shell.execute_reply.started":"2024-03-28T15:38:35.616366Z"},"trusted":true},"outputs":[],"source":["global height\n","global width\n","global num_classes\n","global AUTOTUNE\n","\n","def load_labels(data):\n","    names = data['class'].unique().tolist()\n","    return names\n","\n","def load_data(path, data, classes, p_data=None):\n","    images = []\n","    bboxes = []\n","    labels = []\n","    \n","    \n","    for index, row in data.iterrows():\n","        name = row['filename']\n","        x1 = int(row['xmin'])\n","        y1 = int(row['ymin'])\n","        x2 = int(row['xmax'])\n","        y2 = int(row['ymax'])\n","        label = int(row['class_encoded'])\n","        \n","        if p_data == 'train':\n","            image = os.path.join(path, \"train\", name)\n","        elif p_data == 'valid':\n","            image = os.path.join(path, \"valid\" , name)\n","        else:\n","            image = os.path.join(path, \"test\" , name)\n","\n","        bbox = [x1, y1, x2, y2]\n","\n","        images.append(image)\n","        bboxes.append(bbox)\n","        labels.append(label)\n","\n","    return images, bboxes, labels\n","\n","def read_image_bbox(path, bbox, label_index):\n","    path = path.decode()\n","    image = cv2.imread(path, cv2.IMREAD_COLOR)\n","    h, w, _ = image.shape\n","    image = cv2.resize(image, (width, height))\n","    image = (image - 127.5) / 127.5 ## [-1, +1]\n","    image = image.astype(np.float32)\n","\n","    x1, y1, x2, y2 = bbox\n","\n","    norm_x1 = float(x1/w)\n","    norm_y1 = float(y1/h)\n","    norm_x2 = float(x2/w)\n","    norm_y2 = float(y2/h)\n","    norm_bbox = np.array([norm_x1, norm_y1, norm_x2, norm_y2], dtype=np.float32)\n","\n","    label = [0] * num_classes\n","    label[label_index] = 1 #Fix here\n","    class_label = np.array(label, dtype=np.float32)\n","\n","    return image, norm_bbox, class_label\n","\n","def parse(image, bbox, label):\n","    image, bbox, label = tf.numpy_function(read_image_bbox, [image, bbox, label], [tf.float32, tf.float32, tf.float32])\n","    image.set_shape((height, width, 3))\n","    bbox.set_shape((4))\n","    label.set_shape((num_classes))\n","    return (image), (bbox, label)\n","\n","def tf_dataset(images, bboxes, labels, batch_size, shuffle=False):\n","    ds = tf.data.Dataset.from_tensor_slices((images, bboxes, labels))\n","    ds = ds.map(parse, num_parallel_calls=AUTOTUNE)\n","    if shuffle:\n","        ds = ds.cache().shuffle(1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)\n","    else:\n","        ds = ds.cache().batch(batch_size).prefetch(buffer_size=AUTOTUNE)   \n","    return ds\n","\n","def load_dataset(path, data_type, classes):\n","    \n","    train, valid, test = data_type[0], data_type[1], data_type[2]\n","    \n","    train_images, train_bboxes, train_labels = load_data(path, train, classes, 'train')\n","    \n","    valid_images, valid_bboxes, valid_labels = load_data(path, valid, classes, 'valid')\n","    \n","    test_images, test_bboxes, test_labels = load_data(path, test, classes, 'test')\n","\n","    return (train_images, train_bboxes, train_labels), (valid_images, valid_bboxes, valid_labels), (test_images, test_bboxes, test_labels)\n","\n","if __name__ == \"__main__\":\n","\n","    height = 320\n","    width = 320\n","    batch_size = 32\n","    AUTOTUNE = tf.data.AUTOTUNE\n","    \n","    data_type = [train, valid, test]\n","    path = '/kaggle/input/custom-dataset-new'\n","    \n","    classes = load_labels(train)\n","    num_classes = len(classes)\n","    \n","    (train_images, train_bboxes, train_labels), (valid_images, valid_bboxes, valid_labels), (test_images, test_bboxes, test_labels) = load_dataset(path, data_type, classes)\n","    print(f\"Classes: {classes}\")\n","    print(f\"Total class : {num_classes}\")\n","    print(f\"Train: {len(train_images)} - {len(train_bboxes)} - {len(train_labels)}\")\n","    print(f\"Valid: {len(valid_images)} - {len(valid_bboxes)} - {len(valid_labels)}\")\n","    print(f\"Test : {len(test_images)} - {len(test_bboxes)} - {len(test_labels)}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:38:40.863953Z","iopub.status.busy":"2024-03-28T15:38:40.863309Z","iopub.status.idle":"2024-03-28T15:38:41.474512Z","shell.execute_reply":"2024-03-28T15:38:41.473686Z","shell.execute_reply.started":"2024-03-28T15:38:40.863893Z"},"trusted":true},"outputs":[],"source":["train_ds = tf_dataset(train_images, train_bboxes, train_labels, batch_size, shuffle=True)\n","valid_ds = tf_dataset(valid_images, valid_bboxes, valid_labels, batch_size )"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:39:29.221114Z","iopub.status.busy":"2024-03-28T15:39:29.220256Z","iopub.status.idle":"2024-03-28T15:39:43.360349Z","shell.execute_reply":"2024-03-28T15:39:43.359529Z","shell.execute_reply.started":"2024-03-28T15:39:29.221079Z"},"trusted":true},"outputs":[],"source":["for batch in train_ds.take(1):  \n","    (images) ,(bboxes, labels) = batch\n","    for i in range(len(images)): \n","        image = images[i].numpy()  \n","        image = (image * 127.5 + 127.5).astype('uint8')  \n","        bbox = bboxes[i].numpy()  \n","        label = labels[i].numpy() \n","        plt.figure(figsize=(8, 8))\n","        plt.imshow(image[...,::-1])\n","        h, w, _ = image.shape\n","        x1, y1, x2, y2 = bbox * [w, h, w, h]  \n","        plt.gca().add_patch(plt.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='red', facecolor='none'))\n","        class_id = label.argmax()\n","        text = [i for i in class_dict if class_dict[i]== int(class_id)]\n","        plt.title(f\"Label: {text[0]}\")\n","        plt.axis('off')\n","        plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# class Mobilenet_V2():\n","#     def __init__(self, *, inp_shape = (320,320,3), rho = 1.0 , alpha = 1.0, expansion = 6.0, classes = 2, droppout = 0.0):\n","#         assert alpha > 0 and alpha <= 1 ,'Error, my Mobilenet_V2 can only accept  alpha > 0 and alpha <= 1'\n","#         assert rho > 0 and rho <= 1 ,'Error, my Mobilenet_V2 can only accept  rho > 0 and rho <= 1'\n","#         self._inp_shape = inp_shape\n","#         self._rho = rho\n","#         self._alpha = alpha\n","#         self._expansion = expansion\n","#         self._classes = classes\n","#         self._droppout = droppout\n","#     def _depthwiseconv(self, *, strides: int):\n","#         return models.Sequential([\n","#             DepthwiseConv2D(kernel_size= (3,3), strides= strides, padding= 'same' if strides == 1 else 'valid', use_bias= False),\n","#             BatchNormalization(),\n","#             ReLU(max_value= 6.)\n","#         ])\n","#     def _pointwiseconv(self, *, filters: int, linear: bool):\n","#         layer = models.Sequential([\n","#             Conv2D(filters= int(filters * self._alpha), kernel_size= (1,1), strides= (1,1), padding= 'same', use_bias= False),\n","#             BatchNormalization(),\n","#         ])\n","#         if linear == False:\n","#             layer.add(ReLU(max_value= 6.))\n","#         return layer\n","#     def _standardconv(self):\n","#         return models.Sequential([\n","#             Conv2D(filters= 32, kernel_size= (3,3), strides= (2,2), use_bias= False),\n","#             BatchNormalization(),\n","#             ReLU(max_value= 6.)\n","#         ])\n","#     def _inverted_residual_block_(self, x, *, strides_depthwise: int, filter_pointwise: int, expansion: int):\n","#         filter = int(filter_pointwise * self._alpha)\n","#         fx = self._pointwiseconv(filters= filter * expansion, linear= False)(x)\n","#         fx = self._depthwiseconv(strides= strides_depthwise)(fx)\n","#         fx = self._pointwiseconv(filters= filter , linear= True)(fx)\n","#         if strides_depthwise == 1 and x.shape[-1] == filter_pointwise:\n","#             return add([fx,x])\n","#         else:\n","#             return fx\n","#     def _bottleneck_block_(self, x, *,  s: int, c: int, t: int, n: int):\n","#         x = self._inverted_residual_block_(x, strides_depthwise= s, filter_pointwise= c, expansion= t)\n","#         for i in range(n-1):\n","#             x = self._inverted_residual_block_(x, strides_depthwise= 1, filter_pointwise= c, expansion= t)\n","#         return x \n","#     def build(self):\n","#         print(\"Loading model Mobilenetv2...\")\n","#         feature_map = int(self._rho * self._inp_shape[0])\n","#         img_inp = Input(shape= (feature_map, feature_map,3))\n","#         x = self._standardconv()(img_inp)\n","#         x = self._bottleneck_block_(x, s= 1, c= 16, t= 1, n= 1)\n","#         x = self._bottleneck_block_(x, s= 2, c= 24, t= self._expansion, n= 2)\n","#         x = self._bottleneck_block_(x, s= 2, c= 32, t= self._expansion, n= 3)\n","#         x = self._bottleneck_block_(x, s= 2, c= 64, t= self._expansion, n= 4)\n","#         x = self._bottleneck_block_(x, s= 1, c= 96, t= self._expansion, n= 3)\n","#         x = self._bottleneck_block_(x, s= 2, c= 160, t= self._expansion, n= 3)\n","#         x = self._bottleneck_block_(x, s= 1, c= 320, t= self._expansion, n= 1)\n","#         x = self._pointwiseconv(filters= 1280, linear= False)(x)\n","#         x = GlobalAveragePooling2D()(x)\n","#         x = Dropout(self._droppout)(x)\n","        \n","#         bbox = Dense(4, activation=\"sigmoid\", name=\"bbox\")(x)\n","#         label = Dense(self._classes, activation='softmax', name=\"label\")(x)\n","        \n","#         print(\"Success\")\n","        \n","#         return models.Model(img_inp, outputs=[bbox, label])\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# model = Mobilenet_V2(inp_shape=(height,width,3), rho=1.0, alpha=1.0, expansion=6.0, classes=2, droppout=0.5).build()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:40:00.811001Z","iopub.status.busy":"2024-03-28T15:40:00.810616Z","iopub.status.idle":"2024-03-28T15:40:00.846001Z","shell.execute_reply":"2024-03-28T15:40:00.845059Z","shell.execute_reply.started":"2024-03-28T15:40:00.810972Z"},"trusted":true},"outputs":[],"source":["def InceptionV3():\n","    input_layer = Input(shape=(320 , 320 , 3))\n","    \n","    x = StemBlock(input_layer)\n","    \n","    x = InceptionBlock_A(prev_layer = x ,nbr_kernels = 32)\n","    x = InceptionBlock_A(prev_layer = x ,nbr_kernels = 64)\n","    x = InceptionBlock_A(prev_layer = x ,nbr_kernels = 64)\n","    \n","    x = ReductionBlock_A(prev_layer = x )\n","    \n","    x = InceptionBlock_B(prev_layer = x  , nbr_kernels = 128)\n","    x = InceptionBlock_B(prev_layer = x , nbr_kernels = 160)\n","    x = InceptionBlock_B(prev_layer = x , nbr_kernels = 160)\n","    x = InceptionBlock_B(prev_layer = x , nbr_kernels = 192)\n","    \n","#     Aux = auxiliary_classifier(prev_Layer = x)\n","    \n","    x = ReductionBlock_B(prev_layer = x)\n","    \n","    x = InceptionBlock_C(prev_layer = x)\n","    x = InceptionBlock_C(prev_layer = x)\n","    \n","    x = GlobalAveragePooling2D()(x)\n","    x = Dense(units=2048, activation='relu') (x)\n","    x = Dropout(rate = 0.2) (x)\n","    \n","    bbox = Dense(4, activation=\"sigmoid\", name=\"bbox\")(x)\n","    label = Dense(4, activation='softmax', name=\"label\")(x)\n","    \n","    \n","    model = Model(inputs = input_layer , outputs = [bbox , label] , name = 'Inception-V3')\n","    \n","    return model\n","\n","\n","def conv_with_Batch_Normalisation(prev_layer , nbr_kernels , filter_Size , strides =(1,1) , padding = 'same'):\n","    x = Conv2D(filters=nbr_kernels, kernel_size = filter_Size, strides=strides , padding=padding)(prev_layer)\n","    x = BatchNormalization(axis=3)(x)\n","    x = Activation(activation='relu')(x)\n","    return x\n","\n","\n","def StemBlock(prev_layer):\n","    x = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 32, filter_Size=(3,3) , strides=(2,2))\n","    x = conv_with_Batch_Normalisation(x, nbr_kernels = 32, filter_Size=(3,3))\n","    x = conv_with_Batch_Normalisation(x, nbr_kernels = 64, filter_Size=(3,3))\n","    x = MaxPool2D(pool_size=(3,3) , strides=(2,2)) (x)\n","    x = conv_with_Batch_Normalisation(x, nbr_kernels = 80, filter_Size=(1,1))\n","    x = conv_with_Batch_Normalisation(x, nbr_kernels = 192, filter_Size=(3,3))\n","    x = MaxPool2D(pool_size=(3,3) , strides=(2,2)) (x)\n","    return x    \n","    \n","\n","def InceptionBlock_A(prev_layer  , nbr_kernels):\n","    \n","    branch1 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 64, filter_Size = (1,1))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels=96, filter_Size=(3,3))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels=96, filter_Size=(3,3))\n","    \n","    branch2 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels=48, filter_Size=(1,1))\n","    branch2 = conv_with_Batch_Normalisation(branch2, nbr_kernels=64, filter_Size=(3,3)) # may be 3*3\n","    \n","    branch3 = AveragePooling2D(pool_size=(3,3) , strides=(1,1) , padding='same') (prev_layer)\n","    branch3 = conv_with_Batch_Normalisation(branch3, nbr_kernels = nbr_kernels, filter_Size = (1,1))\n","    \n","    branch4 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels=64, filter_Size=(1,1))\n","    \n","    output = concatenate([branch1 , branch2 , branch3 , branch4], axis=3)\n","    \n","    return output\n","\n","\n","def InceptionBlock_B(prev_layer , nbr_kernels):\n","    \n","    branch1 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = nbr_kernels, filter_Size = (1,1))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = nbr_kernels, filter_Size = (7,1))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = nbr_kernels, filter_Size = (1,7))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = nbr_kernels, filter_Size = (7,1))    \n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = 192, filter_Size = (1,7))\n","    \n","    branch2 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = nbr_kernels, filter_Size = (1,1))\n","    branch2 = conv_with_Batch_Normalisation(branch2, nbr_kernels = nbr_kernels, filter_Size = (1,7))\n","    branch2 = conv_with_Batch_Normalisation(branch2, nbr_kernels = 192, filter_Size = (7,1))\n","    \n","    branch3 = AveragePooling2D(pool_size=(3,3) , strides=(1,1) , padding ='same') (prev_layer)\n","    branch3 = conv_with_Batch_Normalisation(branch3, nbr_kernels = 192, filter_Size = (1,1))\n","    \n","    branch4 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 192, filter_Size = (1,1))\n","    \n","    output = concatenate([branch1 , branch2 , branch3 , branch4], axis = 3)\n","    \n","    return output    \n","\n","    \n","def InceptionBlock_C(prev_layer):\n","    \n","    branch1 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 448, filter_Size = (1,1))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = 384, filter_Size = (3,3))\n","    branch1_1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = 384, filter_Size = (1,3))    \n","    branch1_2 = conv_with_Batch_Normalisation(branch1, nbr_kernels = 384, filter_Size = (3,1))\n","    branch1 = concatenate([branch1_1 , branch1_2], axis = 3)\n","    \n","    branch2 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 384, filter_Size = (1,1))\n","    branch2_1 = conv_with_Batch_Normalisation(branch2, nbr_kernels = 384, filter_Size = (1,3))\n","    branch2_2 = conv_with_Batch_Normalisation(branch2, nbr_kernels = 384, filter_Size = (3,1))\n","    branch2 = concatenate([branch2_1 , branch2_2], axis = 3)\n","    \n","    branch3 = AveragePooling2D(pool_size=(3,3) , strides=(1,1) , padding='same')(prev_layer)\n","    branch3 = conv_with_Batch_Normalisation(branch3, nbr_kernels = 192, filter_Size = (1,1))\n","    \n","    branch4 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 320, filter_Size = (1,1))\n","    \n","    output = concatenate([branch1 , branch2 , branch3 , branch4], axis = 3)\n","    \n","    return output\n","\n","\n","def ReductionBlock_A(prev_layer):\n","    \n","    branch1 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 64, filter_Size = (1,1))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = 96, filter_Size = (3,3))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = 96, filter_Size = (3,3) , strides=(2,2) ) #, padding='valid'\n","    \n","    branch2 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 384, filter_Size=(3,3) , strides=(2,2) )\n","    \n","    branch3 = MaxPool2D(pool_size=(3,3) , strides=(2,2) , padding='same')(prev_layer)\n","    \n","    output = concatenate([branch1 , branch2 , branch3], axis = 3)\n","    \n","    return output\n","\n","\n","def ReductionBlock_B(prev_layer):\n","    \n","    branch1 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 192, filter_Size = (1,1))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = 192, filter_Size = (1,7))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = 192, filter_Size = (7,1))\n","    branch1 = conv_with_Batch_Normalisation(branch1, nbr_kernels = 192, filter_Size = (3,3) , strides=(2,2) , padding = 'valid')\n","    \n","    branch2 = conv_with_Batch_Normalisation(prev_layer, nbr_kernels = 192, filter_Size = (1,1) )\n","    branch2 = conv_with_Batch_Normalisation(branch2, nbr_kernels = 320, filter_Size = (3,3) , strides=(2,2) , padding='valid' )\n","\n","    branch3 = MaxPool2D(pool_size=(3,3) , strides=(2,2) )(prev_layer)\n","    \n","    output = concatenate([branch1 , branch2 , branch3], axis = 3)\n","    \n","    return output\n","\n","\n","def auxiliary_classifier(prev_Layer):\n","    x = AveragePooling2D(pool_size=(5,5) , strides=(3,3)) (prev_Layer)\n","    x = conv_with_Batch_Normalisation(x, nbr_kernels = 128, filter_Size = (1,1))\n","    x = Flatten()(x)\n","    x = Dense(units = 768, activation='relu') (x)\n","    x = Dropout(rate = 0.2) (x)\n","    x = Dense(units = 4, activation='softmax') (x)\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:40:04.262310Z","iopub.status.busy":"2024-03-28T15:40:04.261952Z","iopub.status.idle":"2024-03-28T15:40:05.908342Z","shell.execute_reply":"2024-03-28T15:40:05.907499Z","shell.execute_reply.started":"2024-03-28T15:40:04.262282Z"},"trusted":true},"outputs":[],"source":["model = InceptionV3()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-03-28T15:40:08.399800Z","iopub.status.busy":"2024-03-28T15:40:08.398944Z","iopub.status.idle":"2024-03-28T15:40:08.812752Z","shell.execute_reply":"2024-03-28T15:40:08.811771Z","shell.execute_reply.started":"2024-03-28T15:40:08.399766Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["model.summary()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T15:52:12.888428Z","iopub.status.busy":"2024-03-28T15:52:12.887585Z","iopub.status.idle":"2024-03-28T15:52:12.902864Z","shell.execute_reply":"2024-03-28T15:52:12.901954Z","shell.execute_reply.started":"2024-03-28T15:52:12.888397Z"},"trusted":true},"outputs":[],"source":["import math\n","\n","def ciou_loss(target,  output):\n","    \n","    target = target * tf.cast(target != 0, tf.float32)\n","    output = output * tf.cast(target != 0, tf.float32)\n","\n","    x1g, y1g, x2g, y2g = tf.split(value=target, num_or_size_splits=4, axis=1)\n","    x1, y1, x2, y2 = tf.split(value=output, num_or_size_splits=4, axis=1)\n","    \n","    w_pred = x2 - x1\n","    h_pred = y2 - y1\n","    w_gt = x2g - x1g\n","    h_gt = y2g - y1g\n","\n","    x_center = (x2 + x1) / 2\n","    y_center = (y2 + y1) / 2\n","    x_center_g = (x1g + x2g) / 2\n","    y_center_g = (y1g + y2g) / 2\n","\n","    xc1 = tf.minimum(x1, x1g)\n","    yc1 = tf.minimum(y1, y1g)\n","    xc2 = tf.maximum(x2, x2g)\n","    yc2 = tf.maximum(y2, y2g)\n","    \n","    ###iou term###\n","    xA = tf.maximum(x1g, x1)\n","    yA = tf.maximum(y1g, y1)\n","    xB = tf.minimum(x2g, x2)\n","    yB = tf.minimum(y2g, y2)\n","\n","    interArea = tf.maximum(0.0, (xB - xA + 1)) * tf.maximum(0.0, yB - yA + 1)\n","\n","    boxAArea = (x2g - x1g +1) * (y2g - y1g +1)\n","    boxBArea = (x2 - x1 +1) * (y2 - y1 +1)\n","\n","    iouk = interArea / (boxAArea + boxBArea - interArea + 1e-10)\n","    ###\n","    \n","    ###distance term###\n","    c = ((xc2 - xc1) ** 2) + ((yc2 - yc1) ** 2) +1e-7\n","    d = ((x_center - x_center_g) ** 2) + ((y_center - y_center_g) ** 2)\n","    u = d / c\n","    ###\n","\n","    ###aspect-ratio term###\n","    arctan = tf.atan(w_gt/(h_gt + 1e-10))-tf.atan(w_pred/(h_pred + 1e-10))\n","    v = (4 / (math.pi ** 2)) * tf.pow((tf.atan(w_gt/(h_gt + 1e-10))-tf.atan(w_pred/(h_pred + 1e-10))),2)\n","    S = 1 - iouk\n","    alpha = v / (S + v + 1e-10)\n","    w_temp = 2 * w_pred\n","    ar = (8 / (math.pi ** 2)) * arctan * ((w_pred - w_temp) * h_pred)\n","    ###\n","    \n","    ###calculate ciou###\n","    ciouk = iouk - (u + alpha * ar)\n","    ciouk = (1 - ciouk)\n","    ###\n","    \n","    return ciouk"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-03-28T15:52:15.282977Z","iopub.status.busy":"2024-03-28T15:52:15.282329Z","iopub.status.idle":"2024-03-28T17:25:55.689845Z","shell.execute_reply":"2024-03-28T17:25:55.688968Z","shell.execute_reply.started":"2024-03-28T15:52:15.282950Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["lr = 1e-4  \n","num_epochs = 200\n","\n","model.compile(\n","    loss = {\n","#         \"bbox\": BinaryCrossentropy(from_logits=False),\n","        \"bbox\": ciou_loss,\n","        \"label\": CategoricalCrossentropy(from_logits=False) ,\n","    },\n","    optimizer=Adam(lr),\n","    metrics={\n","        \"bbox\": ['acc'], \n","        \"label\": ['acc'] \n","    }\n",")\n","\n","callbacks = [\n","    ModelCheckpoint('best_model.keras', verbose=1, save_best_only=True),\n","    ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=20, min_lr=1e-6, verbose=1),\n","    CSVLogger('log.csv', append=True),\n","    EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=False, verbose=1),\n","]\n","\n","history= model.fit(\n","    train_ds,\n","    epochs=num_epochs,\n","    validation_data=valid_ds,\n","    callbacks=callbacks\n",")\n","model.save('final_model.keras')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:28:29.692542Z","iopub.status.busy":"2024-03-28T17:28:29.692154Z","iopub.status.idle":"2024-03-28T17:28:30.459042Z","shell.execute_reply":"2024-03-28T17:28:30.457920Z","shell.execute_reply.started":"2024-03-28T17:28:29.692513Z"},"trusted":true},"outputs":[],"source":["plt.figure(figsize=(18,6))\n","\n","plt.subplot(1, 3, 1)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('Model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epochs')\n","plt.legend(['train','valid'], loc='upper right')\n","\n","plt.subplot(1, 3, 2)\n","plt.title('Model bbox accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epochs')\n","plt.plot(history.history['bbox_acc'])\n","plt.plot(history.history['val_bbox_acc'])\n","plt.legend(['train','valid'], loc='upper right')\n","\n","plt.subplot(1, 3, 3)\n","plt.title('Model label accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epochs')\n","plt.plot(history.history['label_acc'])\n","plt.plot(history.history['val_label_acc'])\n","plt.legend(['train','valid'], loc='upper right')\n","\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-03-28T17:37:06.527282Z","iopub.status.busy":"2024-03-28T17:37:06.526625Z","iopub.status.idle":"2024-03-28T17:38:18.238299Z","shell.execute_reply":"2024-03-28T17:38:18.237407Z","shell.execute_reply.started":"2024-03-28T17:37:06.527250Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[],"source":["def cal_iou(y_true, y_pred):\n","    x1 = max(y_true[0], y_pred[0])\n","    y1 = max(y_true[1], y_pred[1])\n","    x2 = min(y_true[2], y_pred[2])\n","    y2 = min(y_true[3], y_pred[3])\n","\n","    intersection_area = max(0, x2 - x1 + 1) * max(0, y2 - y1 + 1)\n","\n","    true_area = (y_true[2] - y_true[0] + 1) * (y_true[3] - y_true[1] + 1)\n","    bbox_area = (y_pred[2] - y_pred[0] + 1) * (y_pred[3] - y_pred[1] + 1)\n","\n","    iou = intersection_area / float(true_area + bbox_area - intersection_area)\n","    return iou\n","\n","if __name__ == \"__main__\":\n","    \n","    model = tf.keras.models.load_model('/kaggle/working/best_model.keras', custom_objects={\"ciou_loss\":ciou_loss})\n","\n","    print(f\"Test : {len(test_images)} - {len(test_bboxes)} - {len(test_labels)}\")\n","\n","    mean_iou = []\n","    pred_labels = []\n","    images = []\n","\n","    for image, true_bbox, true_labels in tqdm(zip(test_images, test_bboxes, test_labels), total=len(test_images)):\n","        name = image.split(\"/\")[-1]\n","\n","        image = cv2.imread(image, cv2.IMREAD_COLOR)\n","        x = cv2.resize(image, (width, height))\n","        x = (x - 127.5) / 127.5\n","        x = np.expand_dims(x, axis=0)\n","        \n","        true_x1, true_y1, true_x2, true_y2 = true_bbox\n","\n","        pred_bbox, label = model.predict(x, verbose=0)\n","        pred_bbox = pred_bbox[0]\n","#         print(pred_bbox)\n","        label_index = np.argmax(label[0])\n","        pred_labels.append(label_index)\n","#         print(label_index)\n","#         print(true_labels)\n","\n","        pred_x1 = int(pred_bbox[0] * image.shape[1])\n","        pred_y1 = int(pred_bbox[1] * image.shape[0])\n","        pred_x2 = int(pred_bbox[2] * image.shape[1])\n","        pred_y2 = int(pred_bbox[3] * image.shape[0])\n","\n","        iou = cal_iou(true_bbox, [pred_x1, pred_y1, pred_x2, pred_y2])\n","        mean_iou.append(iou)\n","\n","        image = cv2.rectangle(image, (true_x1, true_y1), (true_x2, true_y2), (255, 0, 0), 2) ## BLUE\n","        image = cv2.rectangle(image, (pred_x1, pred_y1), (pred_x2, pred_y2), (0, 0, 255), 2) ## RED\n","        \n","        font_size = 1.5\n","        pred_class_name = [i for i in class_dict if class_dict[i]== int(label_index)]\n","        cv2.putText(image, str(pred_class_name[0]) + ' '+ '(pred)', (80, 300), cv2.FONT_HERSHEY_SIMPLEX, font_size, (0, 0, 255), 2)\n","\n","        font_size = 1.5\n","        true_class_name = [i for i in class_dict if class_dict[i]== int(true_labels)]\n","\n","        cv2.putText(image, str(true_class_name[0])+ ' '+ '(true)', (80, 350), cv2.FONT_HERSHEY_SIMPLEX, font_size, (255, 0, 0), 2)\n","\n","        font_size = 1.5\n","        cv2.putText(image, f\"IoU: {iou:.4f}\", (80, 400), cv2.FONT_HERSHEY_SIMPLEX, font_size, (255, 0, 0), 2)\n","        images.append(image)\n","\n","    score = np.mean(mean_iou, axis=0)\n","    mean_acc = accuracy_score(test_labels, pred_labels)\n","    print(f\"Mean IoU: {score:.4f} - Acc: {mean_acc:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-28T17:46:05.687063Z","iopub.status.busy":"2024-03-28T17:46:05.686318Z","iopub.status.idle":"2024-03-28T17:46:15.009540Z","shell.execute_reply":"2024-03-28T17:46:15.005887Z","shell.execute_reply.started":"2024-03-28T17:46:05.687030Z"},"trusted":true},"outputs":[],"source":["import matplotlib.pyplot as plt\n","\n","plt.figure(figsize=(20, 20)) \n","for i in range(len(images[:100])):\n","    ax = plt.subplot(10, 10, i + 1) \n","    plt.imshow(images[i])\n","    plt.axis(\"off\")\n","\n","plt.subplots_adjust(wspace=0, hspace=0)\n","plt.show()"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4608487,"sourceId":7857097,"sourceType":"datasetVersion"}],"dockerImageVersionId":30674,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
